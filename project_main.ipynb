{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlIJt7bxYkL_"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLjafyUSYkMI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijAMhVpdZTco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94899af7-94ea-450a-a9e7-014be3564f5f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYq3N3fTYkMK"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daHNk7CPYkMK"
      },
      "source": [
        "transform_mnist = transform = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "transform_cifar = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N79G1YYeYkMK",
        "outputId": "948df522-2013-40ec-89b6-af3b103f85d5"
      },
      "source": [
        "#create datasets for CIFAR10\n",
        "train_c10_full= torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_cifar)\n",
        "test_c10 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_cifar)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuI3Uo5yYkMM"
      },
      "source": [
        "#create datasets for MNIST\n",
        "train_mnist_full = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform_mnist)\n",
        "test_mnist = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform_mnist)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCHXVBFIljUc"
      },
      "source": [
        "#create datasets for fashion MNIST\n",
        "train_fmnist_full = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform_mnist)\n",
        "test_fmnist = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform_mnist)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjGAWeV0YkMM"
      },
      "source": [
        "#this code needs to be in a function , that generates a training set and validation set from an\n",
        "#input dataset and input minibatch size.  In this case, we call\n",
        "#train_loader, validation_loader = function(train_c10_full, 32)\n",
        "\n",
        "# p between 0 and 1, percent of data in tr_loader, q into validationloader\n",
        "def train_val_split(train_data, minibatch_size, p, q):\n",
        "    idx_range = list(range(0,len(train_data)))\n",
        "    random.shuffle(idx_range)\n",
        "    \n",
        "    p_idx = int(p * len(idx_range))\n",
        "    pq_idx = int((p+q) * len(idx_range))\n",
        "    #middle = len(idx_range)//2\n",
        "    tr_idx = idx_range[:p_idx]\n",
        "    val_idx = idx_range[p_idx:pq_idx]\n",
        "    \n",
        "    train_subset = torch.utils.data.Subset(train_data, tr_idx)\n",
        "    val_subset = torch.utils.data.Subset(train_data, val_idx)\n",
        "    \n",
        "    tr_loader = torch.utils.data.DataLoader(train_subset, batch_size=minibatch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=minibatch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "    return tr_loader, val_loader\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PNzvrVXYkMN"
      },
      "source": [
        "#CIFAR10 dataloaders\n",
        "train_c10_loader, val_c10_loader = train_val_split(train_c10_full, 32, 0.8, 0.2)\n",
        "\n",
        "\n",
        "train_c10_mini, val_c10_mini = train_val_split(train_c10_full, 32, 0.05, 0.05)\n",
        "\n",
        "\n",
        "test_c10_loader = torch.utils.data.DataLoader(test_c10, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "#MNIST dataloaders\n",
        "train_mnist_loader,  val_mnist_loader = train_val_split(train_mnist_full, 32, 0.8, 0.2)\n",
        "\n",
        "test_mnist_loader = torch.utils.data.DataLoader(test_mnist, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "#Fashion-MNIST dataloaders\n",
        "train_fmnist_loader,  val_fmnist_loader = train_val_split(train_fmnist_full, 32, 0.8, 0.2)\n",
        "\n",
        "test_fmnist_loader = torch.utils.data.DataLoader(test_fmnist, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "c10_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "mnist_classes = ('0','1','2','3','4','5','6','7','8','9')\n",
        "\n",
        "fmnist_classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU1TpSWMYkMN",
        "outputId": "2e7c2d65-b4be-44a0-9ae2-24772d2ce9d5"
      },
      "source": [
        "print(train_fmnist_full)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLR8GumYkMN"
      },
      "source": [
        "#un-normalize and display an imaage from a dataset\n",
        "def imshow(img):\n",
        "        img = img / 2 + 0.5     # unnormalize\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        plt.show()\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqIu65FxYkMN"
      },
      "source": [
        "#show_sample will display the first minibatch of dataloader dl\n",
        "#with the first 4 images labeled according to dl_classes\n",
        "def show_samples(dl, dl_classes):\n",
        "\n",
        "    # get some random training images\n",
        "    dataiter = iter(dl)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % dl_classes[labels[j]] for j in range(4)))\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBcwzMhYYkMO",
        "scrolled": true
      },
      "source": [
        "#show_samples(test_fmnist_loader, fmnist_classes)\n",
        "#show_samples(test_c10_loader, c10_classes)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGNJ-dnAYkMO"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BpyRoXQYkMP"
      },
      "source": [
        "# This section is where we explore different NN architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ducKMwggYkMP"
      },
      "source": [
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIXmX_hIYkMP",
        "outputId": "327d286a-01f1-4dde-b478-0697deaecf7f"
      },
      "source": [
        "print(MNISTNet())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNISTNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBYI65PfYkMP"
      },
      "source": [
        "class c10Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(c10Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9JLrcWMYkMQ",
        "outputId": "74172ed5-ed66-4796-df19-1b029df712f4"
      },
      "source": [
        "print('hey bud')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hey bud\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KH9g3M-a5db"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNv66K4fYkMQ"
      },
      "source": [
        "#compute the accuracy of net net identifying the classes of data in the dataloader dl\n",
        "def compute_accuracy(net, dl):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in dl:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhwjR4FoY9D5"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn4AiTuwYkMQ"
      },
      "source": [
        "#train net with a specified number of epochs\n",
        "def train_net_bounded(net, hyper, trainloader, validationloader, print_mode = False):\n",
        "    (num_epochs, learning_rate, momentum) = hyper\n",
        "    \n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    train_start = time.time()\n",
        "\n",
        "    net = net.to(device)\n",
        "    \n",
        "    # loop until the validation accuracy stagnates for 5 epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        tot_train_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tot_train_loss += loss.item()\n",
        "\n",
        "\n",
        "        \n",
        "        # train_acc = compute_accuracy(net, trainloader)\n",
        "        # val_acc = compute_accuracy(net, validationloader)\n",
        "        \n",
        "        tot_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for (images, labels) in validationloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                predictions = net(images)\n",
        "                batch_val_loss = criterion(predictions, labels)\n",
        "                tot_val_loss += batch_val_loss.item() \n",
        "\n",
        "\n",
        "\n",
        "        avg_train_loss = tot_train_loss / len(trainloader)\n",
        "        avg_val_loss = tot_val_loss / len(validationloader)\n",
        "        current = time.time()\n",
        "        \n",
        "        if(print_mode):\n",
        "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
        "                 (epoch + 1,avg_train_loss,avg_val_loss, current-train_start))\n",
        "\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "        val_loss_list.append(avg_val_loss)\n",
        "        \n",
        "    train_end = time.time()\n",
        "    \n",
        "    print('Finished Training')\n",
        "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
        "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
        "    return(train_loss_list, val_loss_list, train_end-train_start)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDYY7k1yQznL"
      },
      "source": [
        "#a modification of the above, where we train until the validation accuracy stops improving.\n",
        "#Will it work?\n",
        "def train_net_unbounded(net, hyper, trainloader, validationloader, print_mode = False):\n",
        "    (learning_rate, momentum) = hyper\n",
        "    \n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    train_start = time.time()\n",
        "\n",
        "    net = net.to(device)\n",
        "    \n",
        "    epoch = 0\n",
        "    # loop until the validation accuracy stagnates for 5 epochs\n",
        "    while (len(val_loss_list) < 20 or val_loss_list[epoch-1] < val_loss_list[epoch - 10]):\n",
        "        tot_train_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tot_train_loss += loss.item()\n",
        "\n",
        "\n",
        "            \n",
        "        epoch+=1\n",
        "        \n",
        "        # train_acc = compute_accuracy(net, trainloader)\n",
        "        # val_acc = compute_accuracy(net, validationloader)\n",
        "        \n",
        "        tot_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for (images, labels) in validationloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                predictions = net(images)\n",
        "                batch_val_loss = criterion(predictions, labels)\n",
        "                tot_val_loss += batch_val_loss.item() \n",
        "\n",
        "\n",
        "\n",
        "        avg_train_loss = tot_train_loss / len(trainloader)\n",
        "        avg_val_loss = tot_val_loss / len(validationloader)\n",
        "        current = time.time()\n",
        "        \n",
        "        if(print_mode):\n",
        "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
        "                 (epoch,avg_train_loss,avg_val_loss, current-train_start))\n",
        "\n",
        "        train_loss_list.append(avg_train_loss)\n",
        "        val_loss_list.append(avg_val_loss)\n",
        "        \n",
        "    train_end = time.time()\n",
        "    \n",
        "    print('Finished Training')\n",
        "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
        "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
        "    return(train_loss_list, val_loss_list, train_end-train_start)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "1lOCh2rcYkMR",
        "outputId": "9530a0fc-b540-4f71-9fe7-514c9b10d6f9"
      },
      "source": [
        "net = c10Net()\n",
        "train_loss_list, validation_loss_list, _ = train_net_unbounded(net, (0.0001,0.9), train_c10_loader, val_c10_loader, True)\n",
        "#t1, v1 = train_acc_list, validation_acc_list"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-64fba237f95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc10Net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net_unbounded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_c10_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_c10_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#t1, v1 = train_acc_list, validation_acc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-0aab32bc9b7a>\u001b[0m in \u001b[0;36mtrain_net_unbounded\u001b[0;34m(net, hyper, trainloader, validationloader, print_mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtot_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9irlN7GBfqNw"
      },
      "source": [
        ""
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EiezPL3YkMS"
      },
      "source": [
        "Let's quickly save our trained model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTMA3TZYkMS"
      },
      "source": [
        "# PATH = './cifar_net.pth'\n",
        "# PATH_MNIST = './mnist_net.pth'\n",
        "# torch.save(net.state_dict(), PATH_MNIST)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nANoDxGjYkMS"
      },
      "source": [
        "# net = Net()\n",
        "# net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIgHxZRHYkMS"
      },
      "source": [
        "def plot_losses(train_history, val_history):\n",
        "\n",
        "    colors = ['r','b']\n",
        "    \n",
        "    x = np.arange(1, len(train_history) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n",
        "    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"Evolution of the training and validation loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "tJP6jz-0QznO",
        "outputId": "66a22903-6428-48fe-b576-8e2d2c771a52"
      },
      "source": [
        "plot_losses(train_loss_list, validation_loss_list)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgiZ7oJ4py8r"
      },
      "source": [
        "#ADAPTED FROM GOOGLE COLAB PYTORCH TUTORIAL\r\n",
        "def dataset_accuracy(net, data_loader, name=\"\"):\r\n",
        "    net = net.to(device)\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for images, labels in data_loader:\r\n",
        "        images, labels = images.to(device), labels.to(device)\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs, 1)\r\n",
        "        total += labels.size(0)\r\n",
        "        correct += (predicted == labels).sum()\r\n",
        "    accuracy = 100 * float(correct) / total\r\n",
        "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\r\n",
        "\r\n",
        "def compute_accuracy(net, train, val, test):\r\n",
        "    dataset_accuracy(net, train, \"training\")\r\n",
        "    dataset_accuracy(net, val, \"validation\")\r\n",
        "    dataset_accuracy(net, test, \"testing\")\r\n",
        "print(\"Computing accuracy...\")\r\n",
        "compute_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmTlNUIdp41t"
      },
      "source": [
        "#FROM GOOGLE COLAB TUTORIAL\r\n",
        "def accuracy_per_class(net):\r\n",
        "    net = net.to(device)\r\n",
        "    n_classes = 10\r\n",
        "    # (real, predicted)\r\n",
        "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)\r\n",
        "\r\n",
        "    for images, labels in test_loader:\r\n",
        "        images, labels = images, labels = images.to(device), labels.to(device)\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        for i in range(test_batch_size):\r\n",
        "            confusion_matrix[labels[i], predicted[i]] += 1\r\n",
        "            label = labels[i]\r\n",
        "\r\n",
        "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\r\n",
        "    for i in range(n_classes):\r\n",
        "        class_total = confusion_matrix[i, :].sum()\r\n",
        "        class_correct = confusion_matrix[i, i]\r\n",
        "        percentage_correct = 100.0 * float(class_correct) / class_total\r\n",
        "        \r\n",
        "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\r\n",
        "    return confusion_matrix\r\n",
        "\r\n",
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9LD2wIeYkMT"
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "How do we run these neural networks on the GPU?\n",
        "\n",
        "Training on GPU\n",
        "----------------\n",
        "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
        "net onto the GPU.\n",
        "\n",
        "Let's first define our device as the first visible cuda device if we have\n",
        "CUDA available:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQNFTsluYkMT"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTpAv4uTYkMT"
      },
      "source": [
        "The rest of this section assumes that ``device`` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is really small.\n",
        "\n",
        "**Exercise:** Try increasing the width of your network (argument 2 of\n",
        "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` \n",
        "they need to be the same number), see what kind of speedup you get.\n",
        "\n",
        "**Goals achieved**:\n",
        "\n",
        "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
        "- Train a small neural network to classify images\n",
        "\n",
        "Training on multiple GPUs\n",
        "-------------------------\n",
        "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
        "please check out :doc:`data_parallel_tutorial`.\n",
        "\n",
        "Where do I go next?\n",
        "-------------------\n",
        "\n",
        "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
        "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
        "-  `Train a face generator using Generative Adversarial Networks`_\n",
        "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
        "-  `More examples`_\n",
        "-  `More tutorials`_\n",
        "-  `Discuss PyTorch on the Forums`_\n",
        "-  `Chat with other users on Slack`_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEPSKD7vYkMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}