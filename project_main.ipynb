{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VlIJt7bxYkL_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FB-Wqlcb6H3_",
    "outputId": "2eebb699-ee2c-4bba-f063-97c811900c8d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TLjafyUSYkMI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijAMhVpdZTco",
    "outputId": "6ca4c88b-d66d-4f3a-ac0d-212ce5438bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hudson\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYq3N3fTYkMK"
   },
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "daHNk7CPYkMK"
   },
   "outputs": [],
   "source": [
    "transform_mnist = transform = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "transform_cifar = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N79G1YYeYkMK",
    "outputId": "3b4f46fb-7ee8-4037-fea5-91366ebaaba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#create datasets for CIFAR10\n",
    "train_c10_full= torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_cifar)\n",
    "test_c10 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TuI3Uo5yYkMM"
   },
   "outputs": [],
   "source": [
    "#create datasets for MNIST\n",
    "train_mnist_full = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform_mnist)\n",
    "test_mnist = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KCHXVBFIljUc"
   },
   "outputs": [],
   "source": [
    "#create datasets for fashion MNIST\n",
    "train_fmnist_full = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform_mnist)\n",
    "test_fmnist = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XjGAWeV0YkMM"
   },
   "outputs": [],
   "source": [
    "#this code needs to be in a function , that generates a training set and validation set from an\n",
    "#input dataset and input minibatch size.  In this case, we call\n",
    "#train_loader, validation_loader = function(train_c10_full, 32)\n",
    "\n",
    "# p between 0 and 1, percent of data in tr_loader, q into validationloader\n",
    "def train_val_split(train_data, minibatch_size, p, q):\n",
    "    idx_range = list(range(0,len(train_data)))\n",
    "    random.shuffle(idx_range)\n",
    "    \n",
    "    p_idx = int(p * len(idx_range))\n",
    "    pq_idx = int((p+q) * len(idx_range))\n",
    "    #middle = len(idx_range)//2\n",
    "    tr_idx = idx_range[:p_idx]\n",
    "    val_idx = idx_range[p_idx:pq_idx]\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(train_data, tr_idx)\n",
    "    val_subset = torch.utils.data.Subset(train_data, val_idx)\n",
    "    \n",
    "    tr_loader = torch.utils.data.DataLoader(train_subset, batch_size=minibatch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=minibatch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    return tr_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_PNzvrVXYkMN"
   },
   "outputs": [],
   "source": [
    "#CIFAR10 dataloaders\n",
    "train_c10_loader, val_c10_loader = train_val_split(train_c10_full, 32, 0.8, 0.2)\n",
    "\n",
    "\n",
    "train_c10_mini, val_c10_mini = train_val_split(train_c10_full, 32, 0.05, 0.05)\n",
    "\n",
    "\n",
    "test_c10_loader = torch.utils.data.DataLoader(test_c10, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#MNIST dataloaders\n",
    "train_mnist_loader,  val_mnist_loader = train_val_split(train_mnist_full, 32, 0.8, 0.2)\n",
    "\n",
    "test_mnist_loader = torch.utils.data.DataLoader(test_mnist, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "#Fashion-MNIST dataloaders\n",
    "train_fmnist_loader,  val_fmnist_loader = train_val_split(train_fmnist_full, 32, 0.8, 0.2)\n",
    "\n",
    "test_fmnist_loader = torch.utils.data.DataLoader(test_fmnist, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "c10_classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "mnist_classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "\n",
    "fmnist_classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bU1TpSWMYkMN",
    "outputId": "57e49551-3cc4-4f17-fdf4-e374ccea5503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=0.5, std=0.5)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_fmnist_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LzLR8GumYkMN"
   },
   "outputs": [],
   "source": [
    "#un-normalize and display an imaage from a dataset\n",
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VBFWS-9N1T0H"
   },
   "outputs": [],
   "source": [
    "#Adapted from google's tutorial\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    :param cm: (numpy matrix) confusion matrix\n",
    "    :param classes: [str]\n",
    "    :param normalize: (bool)\n",
    "    :param title: (str)\n",
    "    :param cmap: (matplotlib color map)\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 8))   \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OqIu65FxYkMN"
   },
   "outputs": [],
   "source": [
    "#show_sample will display the first minibatch of dataloader dl\n",
    "#with the first 4 images labeled according to dl_classes\n",
    "def show_samples(dl, dl_classes):\n",
    "\n",
    "    # get some random training images\n",
    "    dataiter = iter(dl)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # show images\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    # print labels\n",
    "    print(' '.join('%5s' % dl_classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kBcwzMhYYkMO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show_samples(test_fmnist_loader, fmnist_classes)\n",
    "#show_samples(test_c10_loader, c10_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fGNJ-dnAYkMO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BpyRoXQYkMP"
   },
   "source": [
    "# This section is where we explore different NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ducKMwggYkMP"
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIXmX_hIYkMP",
    "outputId": "c4bf1ead-f732-4935-eb9d-c38ba934677f"
   },
   "outputs": [],
   "source": [
    "print(MNISTNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fBYI65PfYkMP"
   },
   "outputs": [],
   "source": [
    "class c10Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c10Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9JLrcWMYkMQ",
    "outputId": "e98bd30d-8d29-4e86-b45e-201dc2eb7fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey bud\n"
     ]
    }
   ],
   "source": [
    "print('hey bud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0KH9g3M-a5db"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VNv66K4fYkMQ"
   },
   "outputs": [],
   "source": [
    "#compute the accuracy of net net identifying the classes of data in the dataloader dl\n",
    "def compute_accuracy(net, dl):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.to(device)\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhwjR4FoY9D5"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Gn4AiTuwYkMQ"
   },
   "outputs": [],
   "source": [
    "#train net with a specified number of\n",
    "def train_net_bounded(net, hyper, trainloader, validationloader, print_mode = False):\n",
    "    (num_epochs, learning_rate, momentum) = hyper\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_start = time.time()\n",
    "\n",
    "    net = net.to(device)\n",
    "    \n",
    "    # loop until the validation accuracy stagnates for 5 epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        tot_train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "        # train_acc = compute_accuracy(net, trainloader)\n",
    "        # val_acc = compute_accuracy(net, validationloader)\n",
    "        \n",
    "        tot_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in validationloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                predictions = net(images)\n",
    "                batch_val_loss = criterion(predictions, labels)\n",
    "                tot_val_loss += batch_val_loss.item() \n",
    "\n",
    "\n",
    "\n",
    "        avg_train_loss = tot_train_loss / len(trainloader)\n",
    "        avg_val_loss = tot_val_loss / len(validationloader)\n",
    "        current = time.time()\n",
    "        \n",
    "        if(print_mode):\n",
    "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
    "                 (epoch,avg_train_loss,avg_val_loss, current-train_start))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        \n",
    "    train_end = time.time()\n",
    "    \n",
    "    print('Finished Training')\n",
    "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
    "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
    "    return(train_loss_list, val_loss_list, train_end-train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CDYY7k1yQznL"
   },
   "outputs": [],
   "source": [
    "#a modification of the above, where we train until the validation accuracy stops improving.\n",
    "#Will it work?\n",
    "def train_net_unbounded(net, hyper, trainloader, validationloader,path, print_mode = False):\n",
    "    (learning_rate, momentum) = hyper\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_start = time.time()\n",
    "\n",
    "    net = net.to(device)\n",
    "    \n",
    "    best_val_loss = 100 #arbitrarily large number\n",
    "    epoch = 0\n",
    "    # loop until the validation accuracy stagnates for 5 epochs\n",
    "    while (len(val_loss_list) < 20 or val_loss_list[epoch-1] < val_loss_list[epoch - 10]):\n",
    "        tot_train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_train_loss += loss.item()\n",
    "\n",
    "        epoch+=1\n",
    "        \n",
    "        # train_acc = compute_accuracy(net, trainloader)\n",
    "        # val_acc = compute_accuracy(net, validationloader)\n",
    "        \n",
    "        tot_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in validationloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                predictions = net(images)\n",
    "                batch_val_loss = criterion(predictions, labels)\n",
    "                tot_val_loss += batch_val_loss.item() \n",
    "\n",
    "\n",
    "\n",
    "        avg_train_loss = tot_train_loss / len(trainloader)\n",
    "        avg_val_loss = tot_val_loss / len(validationloader)\n",
    "        current = time.time()\n",
    "        \n",
    "        if (avg_val_loss < best_val_loss):\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "        if(print_mode):\n",
    "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
    "                 (epoch,avg_train_loss,avg_val_loss, current-train_start))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        \n",
    "    train_end = time.time()\n",
    "    \n",
    "    print('Finished Training after %fs' % (train_end - train_start))\n",
    "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
    "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
    "    return(train_loss_list, val_loss_list, train_end-train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "1lOCh2rcYkMR",
    "outputId": "3916629f-f06d-41d3-e7d0-799d1be1b1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 2.301781 Val Loss: 2.298384 Time: 11s\n",
      "Epoch: 2 Train Loss: 2.292041 Val Loss: 2.278740 Time: 25s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e77eca02db7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msave_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lanet_cifar1.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhyper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(learning_rate, momentum)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_net_unbounded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_c10_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_c10_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#t1, v1 = train_acc_list, validation_acc_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-f9fa863a1d85>\u001b[0m in \u001b[0;36mtrain_net_unbounded\u001b[1;34m(net, hyper, trainloader, validationloader, path, print_mode)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtot_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = c10Net()\n",
    "save_name = 'lanet_cifar1.pth'\n",
    "hyper = (0.01,0.9) #(learning_rate, momentum)\n",
    "train_loss_list, validation_loss_list, t = train_net_unbounded(net, hyper, train_c10_mini, val_c10_mini, save_name, True)\n",
    "#t1, v1 = train_acc_list, validation_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYIKjZWtCmyE"
   },
   "source": [
    "#Now we grid search over our hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "ibSq0AQUHCHS",
    "outputId": "d419cf1a-a6ae-47df-c2d4-73f00adb722c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kh70R74TFXUI",
    "outputId": "6064938e-a781-4f11-a7ec-a5502946d7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.1, 0.05, 0.01, 0.001],\n",
    "    'm' : [0.7, 0.8, 0.9, 0.95]\n",
    "}\n",
    "params_dummy = {\n",
    "    'lr': [0.1],\n",
    "    'm' : [0.7]\n",
    "}\n",
    "print(type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PGropZ-1G48h"
   },
   "outputs": [],
   "source": [
    "def grid_search_net(net, trainloader, validationloader, out_path, params):\n",
    "    start = time.time()\n",
    "    temp_path = \"temp.pth\"\n",
    "    lrs, ms = params['lr'], params['m']\n",
    "    best_val_loss, best_t, best_trList, best_valList, best_lr, best_m = 100, 0, [], [], 0, 0\n",
    "    for lr in lrs:\n",
    "        for m in ms:\n",
    "            print('Trying Learning Rate %f and Momentum %f' % (lr,m))\n",
    "            trList, valList, t = train_net_unbounded(net, (lr,m), trainloader, validationloader, temp_path, False)\n",
    "            if min(valList) < best_val_loss:\n",
    "                best_val_loss, best_t, best_trList, best_valList, best_lr, best_m = min(valList), t, trList, valList, lr, m\n",
    "                net.load_state_dict(torch.load(temp_path))\n",
    "                torch.save(net.state_dict(), out_path)\n",
    "    end = time.time()\n",
    "    print('Best Validation Loss: %f' % best_val_loss)\n",
    "    print('Best Learning Rate: %f' % best_lr)\n",
    "    print('Best Momentum: %f' % best_m)\n",
    "    print('Total time elapsed %ds' % (end - start))\n",
    "    return best_trList, best_valList, best_t, best_lr, best_m\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9irlN7GBfqNw",
    "outputId": "f81d2ba7-14a1-4c44-cf91-d055c872a44e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Learning Rate 0.100000 and Momentum 0.700000\n"
     ]
    }
   ],
   "source": [
    "x = c10Net()\n",
    "out = 'grid_search_lanet_cifar10.pth'\n",
    "tr, val, t, lr, m = grid_search_net(x, train_c10_mini, val_c10_mini, out, params_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPTMA3TZYkMS"
   },
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# PATH_MNIST = './mnist_net.pth'\n",
    "# torch.save(net.state_dict(), PATH_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nANoDxGjYkMS",
    "outputId": "9d80c7e8-37b0-4f50-e002-085c9aa21d0b"
   },
   "outputs": [],
   "source": [
    "# net = c10Net()\n",
    "# net.load_state_dict(torch.load(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "gIgHxZRHYkMS",
    "outputId": "096942db-1ec6-416e-97ba-869d849ff1ca"
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_history, val_history, t, hyper):\n",
    "\n",
    "    colors = ['r','b']\n",
    "    \n",
    "    x = np.arange(1, len(train_history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n",
    "    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Evolution of the training and validation loss\")\n",
    "    plt.show()\n",
    "    (lr, m) = hyper\n",
    "    print('Elapsed: %ds Learning Rate: %d Momentum: %d'% (t, lr, m))\n",
    "\n",
    "plot_losses(train_loss_list, validation_loss_list, t, hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "tJP6jz-0QznO",
    "outputId": "de64518c-b744-4379-ed90-69790be517e3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl9ZPpXH3a_t"
   },
   "source": [
    "# This next section is adapted directly from a Google Colab tutorial\n",
    "The tutorial can be found here: https://colab.research.google.com/drive/1B5KQvPySqYEa6XicRHdOwgv8fN1BrCgQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in a dataset that was saved earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgiZ7oJ4py8r"
   },
   "outputs": [],
   "source": [
    "#ADAPTED FROM GOOGLE COLAB PYTORCH TUTORIAL\n",
    "def dataset_accuracy(net, data_loader, name=\"\"):\n",
    "    net = net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    accuracy = 100 * float(correct) / total\n",
    "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n",
    "\n",
    "def compute_accuracy(net, train, val, test):\n",
    "    dataset_accuracy(net, train, \"training\")\n",
    "    dataset_accuracy(net, val, \"validation\")\n",
    "    dataset_accuracy(net, test, \"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDsudWK9ylOv",
    "outputId": "d490d831-1acf-42be-c9ac-feb12f02cf9b"
   },
   "outputs": [],
   "source": [
    "compute_accuracy(net, train_c10_loader, val_c10_loader, test_c10_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmTlNUIdp41t",
    "outputId": "10c27c3d-61a4-4f2f-a7c1-9ac6a6e6b3ed"
   },
   "outputs": [],
   "source": [
    "#FROM GOOGLE COLAB TUTORIAL\n",
    "def accuracy_per_class(net, classes, testloader):\n",
    "    net = net.to(device)\n",
    "    # (real, predicted)\n",
    "    confusion_matrix = np.zeros((len(classes), len(classes)), dtype=np.int64)\n",
    "\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for i in range(16):\n",
    "            confusion_matrix[labels[i], predicted[i]] += 1\n",
    "            label = labels[i]\n",
    "\n",
    "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n",
    "    for i in range(len(classes)):\n",
    "        class_total = confusion_matrix[i, :].sum()\n",
    "        class_correct = confusion_matrix[i, i]\n",
    "        percentage_correct = 100.0 * float(class_correct) / class_total\n",
    "        \n",
    "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix = accuracy_per_class(net, c10_classes, test_c10_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hjRSLqjA1GkD",
    "outputId": "2c1a504b-4cc2-4e94-e2a9-c8240733b3ea"
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, c10_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, c10_classes,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9LD2wIeYkMT"
   },
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQNFTsluYkMT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTpAv4uTYkMT"
   },
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` â€“\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEPSKD7vYkMU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
