{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VlIJt7bxYkL_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FB-Wqlcb6H3_",
    "outputId": "2eebb699-ee2c-4bba-f063-97c811900c8d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TLjafyUSYkMI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijAMhVpdZTco",
    "outputId": "6ca4c88b-d66d-4f3a-ac0d-212ce5438bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hudson\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYq3N3fTYkMK"
   },
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "daHNk7CPYkMK"
   },
   "outputs": [],
   "source": [
    "transform_mnist = transform = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "transform_cifar = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N79G1YYeYkMK",
    "outputId": "3b4f46fb-7ee8-4037-fea5-91366ebaaba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#create datasets for CIFAR10\n",
    "train_c10_full= torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_cifar)\n",
    "test_c10 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TuI3Uo5yYkMM"
   },
   "outputs": [],
   "source": [
    "#create datasets for MNIST\n",
    "train_mnist_full = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform_mnist)\n",
    "test_mnist = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KCHXVBFIljUc"
   },
   "outputs": [],
   "source": [
    "#create datasets for fashion MNIST\n",
    "train_fmnist_full = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform_mnist)\n",
    "test_fmnist = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XjGAWeV0YkMM"
   },
   "outputs": [],
   "source": [
    "#this code needs to be in a function , that generates a training set and validation set from an\n",
    "#input dataset and input minibatch size.  In this case, we call\n",
    "#train_loader, validation_loader = function(train_c10_full, 32)\n",
    "\n",
    "# p between 0 and 1, percent of data in tr_loader, q into validationloader\n",
    "def train_val_split(train_data, minibatch_size, p, q):\n",
    "    idx_range = list(range(0,len(train_data)))\n",
    "    random.shuffle(idx_range)\n",
    "    \n",
    "    p_idx = int(p * len(idx_range))\n",
    "    pq_idx = int((p+q) * len(idx_range))\n",
    "    #middle = len(idx_range)//2\n",
    "    tr_idx = idx_range[:p_idx]\n",
    "    val_idx = idx_range[p_idx:pq_idx]\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(train_data, tr_idx)\n",
    "    val_subset = torch.utils.data.Subset(train_data, val_idx)\n",
    "    \n",
    "    tr_loader = torch.utils.data.DataLoader(train_subset, batch_size=minibatch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=minibatch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    return tr_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_PNzvrVXYkMN"
   },
   "outputs": [],
   "source": [
    "#CIFAR10 dataloaders\n",
    "train_c10_loader, val_c10_loader = train_val_split(train_c10_full, 32, 0.8, 0.2)\n",
    "\n",
    "\n",
    "train_c10_mini, val_c10_mini = train_val_split(train_c10_full, 32, 0.05, 0.05)\n",
    "\n",
    "\n",
    "test_c10_loader = torch.utils.data.DataLoader(test_c10, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#MNIST dataloaders\n",
    "train_mnist_loader,  val_mnist_loader = train_val_split(train_mnist_full, 32, 0.8, 0.2)\n",
    "\n",
    "test_mnist_loader = torch.utils.data.DataLoader(test_mnist, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "#Fashion-MNIST dataloaders\n",
    "train_fmnist_loader,  val_fmnist_loader = train_val_split(train_fmnist_full, 32, 0.8, 0.2)\n",
    "\n",
    "test_fmnist_loader = torch.utils.data.DataLoader(test_fmnist, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "c10_classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "mnist_classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "\n",
    "fmnist_classes = ('t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bU1TpSWMYkMN",
    "outputId": "57e49551-3cc4-4f17-fdf4-e374ccea5503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=0.5, std=0.5)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_fmnist_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LzLR8GumYkMN"
   },
   "outputs": [],
   "source": [
    "#un-normalize and display an imaage from a dataset\n",
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VBFWS-9N1T0H"
   },
   "outputs": [],
   "source": [
    "#Adapted from google's tutorial\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    :param cm: (numpy matrix) confusion matrix\n",
    "    :param classes: [str]\n",
    "    :param normalize: (bool)\n",
    "    :param title: (str)\n",
    "    :param cmap: (matplotlib color map)\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 8))   \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OqIu65FxYkMN"
   },
   "outputs": [],
   "source": [
    "#show_sample will display the first minibatch of dataloader dl\n",
    "#with the first 4 images labeled according to dl_classes\n",
    "def show_samples(dl, dl_classes):\n",
    "\n",
    "    # get some random training images\n",
    "    dataiter = iter(dl)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # show images\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    # print labels\n",
    "    print(' '.join('%5s' % dl_classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kBcwzMhYYkMO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show_samples(test_fmnist_loader, fmnist_classes)\n",
    "#show_samples(test_c10_loader, c10_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fGNJ-dnAYkMO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BpyRoXQYkMP"
   },
   "source": [
    "# This section is where we explore different NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ducKMwggYkMP"
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIXmX_hIYkMP",
    "outputId": "c4bf1ead-f732-4935-eb9d-c38ba934677f"
   },
   "outputs": [],
   "source": [
    "print(MNISTNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fBYI65PfYkMP"
   },
   "outputs": [],
   "source": [
    "class c10Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(c10Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9JLrcWMYkMQ",
    "outputId": "e98bd30d-8d29-4e86-b45e-201dc2eb7fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey bud\n"
     ]
    }
   ],
   "source": [
    "print('hey bud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0KH9g3M-a5db"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VNv66K4fYkMQ"
   },
   "outputs": [],
   "source": [
    "#compute the accuracy of net net identifying the classes of data in the dataloader dl\n",
    "def compute_accuracy(net, dl):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.to(device)\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhwjR4FoY9D5"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Gn4AiTuwYkMQ"
   },
   "outputs": [],
   "source": [
    "#train net with a specified number of\n",
    "def train_net_bounded(net, hyper, trainloader, validationloader, print_mode = False):\n",
    "    (num_epochs, learning_rate, momentum) = hyper\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_start = time.time()\n",
    "\n",
    "    net = net.to(device)\n",
    "    \n",
    "    # loop until the validation accuracy stagnates for 5 epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        tot_train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "        # train_acc = compute_accuracy(net, trainloader)\n",
    "        # val_acc = compute_accuracy(net, validationloader)\n",
    "        \n",
    "        tot_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in validationloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                predictions = net(images)\n",
    "                batch_val_loss = criterion(predictions, labels)\n",
    "                tot_val_loss += batch_val_loss.item() \n",
    "\n",
    "\n",
    "\n",
    "        avg_train_loss = tot_train_loss / len(trainloader)\n",
    "        avg_val_loss = tot_val_loss / len(validationloader)\n",
    "        current = time.time()\n",
    "        \n",
    "        if(print_mode):\n",
    "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
    "                 (epoch,avg_train_loss,avg_val_loss, current-train_start))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        \n",
    "    train_end = time.time()\n",
    "    \n",
    "    print('Finished Training')\n",
    "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
    "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
    "    return(train_loss_list, val_loss_list, train_end-train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CDYY7k1yQznL"
   },
   "outputs": [],
   "source": [
    "#a modification of the above, where we train until the validation accuracy stops improving.\n",
    "#Will it work?\n",
    "def train_net_unbounded(net, hyper, trainloader, validationloader,path, print_mode = False):\n",
    "    (learning_rate, momentum) = hyper\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_start = time.time()\n",
    "\n",
    "    net = net.to(device)\n",
    "    \n",
    "    best_val_loss = 100 #arbitrarily large number\n",
    "    epoch = 0\n",
    "    # loop until the validation accuracy stagnates for 5 epochs\n",
    "    while (len(val_loss_list) < 20 or val_loss_list[epoch-1] < val_loss_list[epoch - 10]):\n",
    "        tot_train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_train_loss += loss.item()\n",
    "\n",
    "        epoch+=1\n",
    "        \n",
    "        # train_acc = compute_accuracy(net, trainloader)\n",
    "        # val_acc = compute_accuracy(net, validationloader)\n",
    "        \n",
    "        tot_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in validationloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                predictions = net(images)\n",
    "                batch_val_loss = criterion(predictions, labels)\n",
    "                tot_val_loss += batch_val_loss.item() \n",
    "\n",
    "\n",
    "\n",
    "        avg_train_loss = tot_train_loss / len(trainloader)\n",
    "        avg_val_loss = tot_val_loss / len(validationloader)\n",
    "        current = time.time()\n",
    "        \n",
    "        if (avg_val_loss < best_val_loss):\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(net.state_dict(), path)\n",
    "\n",
    "        if(print_mode):\n",
    "            print('Epoch: %d Train Loss: %f Val Loss: %f Time: %ds' % \\\n",
    "                 (epoch,avg_train_loss,avg_val_loss, current-train_start))\n",
    "\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        val_loss_list.append(avg_val_loss)\n",
    "        \n",
    "    train_end = time.time()\n",
    "    \n",
    "    print('Finished Training after %fs' % (train_end - train_start))\n",
    "    best_epoch = val_loss_list.index(min(val_loss_list)) + 1\n",
    "    print('Best model at epoch: %d with validation loss of %f'  % (best_epoch, val_loss_list[best_epoch - 1]))\n",
    "    return(train_loss_list, val_loss_list, train_end-train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "1lOCh2rcYkMR",
    "outputId": "3916629f-f06d-41d3-e7d0-799d1be1b1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 2.301781 Val Loss: 2.298384 Time: 11s\n",
      "Epoch: 2 Train Loss: 2.292041 Val Loss: 2.278740 Time: 25s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e77eca02db7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msave_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lanet_cifar1.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhyper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(learning_rate, momentum)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_net_unbounded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_c10_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_c10_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#t1, v1 = train_acc_list, validation_acc_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-f9fa863a1d85>\u001b[0m in \u001b[0;36mtrain_net_unbounded\u001b[1;34m(net, hyper, trainloader, validationloader, path, print_mode)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtot_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = c10Net()\n",
    "save_name = 'lanet_cifar1.pth'\n",
    "hyper = (0.01,0.9) #(learning_rate, momentum)\n",
    "train_loss_list, validation_loss_list, t = train_net_unbounded(net, hyper, train_c10_mini, val_c10_mini, save_name, True)\n",
    "#t1, v1 = train_acc_list, validation_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYIKjZWtCmyE"
   },
   "source": [
    "#Now we grid search over our hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "ibSq0AQUHCHS",
    "outputId": "d419cf1a-a6ae-47df-c2d4-73f00adb722c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kh70R74TFXUI",
    "outputId": "6064938e-a781-4f11-a7ec-a5502946d7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.1, 0.05, 0.01, 0.001],\n",
    "    'm' : [0.7, 0.8, 0.9, 0.95]\n",
    "}\n",
    "params_dummy = {\n",
    "    'lr': [0.1],\n",
    "    'm' : [0.7]\n",
    "}\n",
    "print(type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PGropZ-1G48h"
   },
   "outputs": [],
   "source": [
    "def grid_search_net(net, trainloader, validationloader, out_path, params):\n",
    "    start = time.time()\n",
    "    temp_path = \"temp.pth\"\n",
    "    lrs, ms = params['lr'], params['m']\n",
    "    best_val_loss, best_t, best_trList, best_valList, best_lr, best_m = 100, 0, [], [], 0, 0\n",
    "    for lr in lrs:\n",
    "        for m in ms:\n",
    "            print('Trying Learning Rate %f and Momentum %f' % (lr,m))\n",
    "            trList, valList, t = train_net_unbounded(net, (lr,m), trainloader, validationloader, temp_path, False)\n",
    "            if min(valList) < best_val_loss:\n",
    "                best_val_loss, best_t, best_trList, best_valList, best_lr, best_m = min(valList), t, trList, valList, lr, m\n",
    "                net.load_state_dict(torch.load(temp_path))\n",
    "                torch.save(net.state_dict(), out_path)\n",
    "    end = time.time()\n",
    "    print('Best Validation Loss: %f' % best_val_loss)\n",
    "    print('Best Learning Rate: %f' % best_lr)\n",
    "    print('Best Momentum: %f' % best_m)\n",
    "    print('Total time elapsed %ds' % (end - start))\n",
    "    return best_trList, best_valList, best_t, best_lr, best_m\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9irlN7GBfqNw",
    "outputId": "f81d2ba7-14a1-4c44-cf91-d055c872a44e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Learning Rate 0.100000 and Momentum 0.700000\n",
      "Finished Training after 247.940263s\n",
      "Best model at epoch: 9 with validation loss of 1.752953\n",
      "Best Validation Loss: 1.752953\n",
      "Best Learning Rate: 0.100000\n",
      "Best Momentum: 0.700000\n",
      "Total time elapsed 247s\n"
     ]
    }
   ],
   "source": [
    "x = c10Net()\n",
    "out = 'grid_search_lanet_cifar10.pth'\n",
    "tr, val, t, lr, m = grid_search_net(x, train_c10_mini, val_c10_mini, out, params_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IPTMA3TZYkMS"
   },
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# PATH_MNIST = './mnist_net.pth'\n",
    "# torch.save(net.state_dict(), PATH_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nANoDxGjYkMS",
    "outputId": "9d80c7e8-37b0-4f50-e002-085c9aa21d0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net = c10Net()\n",
    "# net.load_state_dict(torch.load(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "gIgHxZRHYkMS",
    "outputId": "096942db-1ec6-416e-97ba-869d849ff1ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 247s Learning Rate: 0 Momentum: 0\n"
     ]
    }
   ],
   "source": [
    "def plot_losses(train_history, val_history, t, hyper):\n",
    "\n",
    "    colors = ['r','b']\n",
    "    \n",
    "    x = np.arange(1, len(train_history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n",
    "    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Evolution of the training and validation loss\")\n",
    "    plt.show()\n",
    "    (lr, m) = hyper\n",
    "    print('Elapsed: %ds Learning Rate: %d Momentum: %d'% (t, lr, m))\n",
    "\n",
    "plot_losses(tr, val, t, (lr,m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "tJP6jz-0QznO",
    "outputId": "de64518c-b744-4379-ed90-69790be517e3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl9ZPpXH3a_t"
   },
   "source": [
    "# This next section is adapted directly from a Google Colab tutorial\n",
    "The tutorial can be found here: https://colab.research.google.com/drive/1B5KQvPySqYEa6XicRHdOwgv8fN1BrCgQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in a dataset that was saved earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgiZ7oJ4py8r"
   },
   "outputs": [],
   "source": [
    "#ADAPTED FROM GOOGLE COLAB PYTORCH TUTORIAL\n",
    "def dataset_accuracy(net, data_loader, name=\"\"):\n",
    "    net = net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    accuracy = 100 * float(correct) / total\n",
    "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n",
    "\n",
    "def compute_accuracy(net, train, val, test):\n",
    "    dataset_accuracy(net, train, \"training\")\n",
    "    dataset_accuracy(net, val, \"validation\")\n",
    "    dataset_accuracy(net, test, \"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDsudWK9ylOv",
    "outputId": "d490d831-1acf-42be-c9ac-feb12f02cf9b"
   },
   "outputs": [],
   "source": [
    "compute_accuracy(net, train_c10_loader, val_c10_loader, test_c10_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmTlNUIdp41t",
    "outputId": "10c27c3d-61a4-4f2f-a7c1-9ac6a6e6b3ed"
   },
   "outputs": [],
   "source": [
    "#FROM GOOGLE COLAB TUTORIAL\n",
    "def accuracy_per_class(net, classes, testloader):\n",
    "    net = net.to(device)\n",
    "    # (real, predicted)\n",
    "    confusion_matrix = np.zeros((len(classes), len(classes)), dtype=np.int64)\n",
    "\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for i in range(16):\n",
    "            confusion_matrix[labels[i], predicted[i]] += 1\n",
    "            label = labels[i]\n",
    "\n",
    "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n",
    "    for i in range(len(classes)):\n",
    "        class_total = confusion_matrix[i, :].sum()\n",
    "        class_correct = confusion_matrix[i, i]\n",
    "        percentage_correct = 100.0 * float(class_correct) / class_total\n",
    "        \n",
    "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix = accuracy_per_class(net, c10_classes, test_c10_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hjRSLqjA1GkD",
    "outputId": "2c1a504b-4cc2-4e94-e2a9-c8240733b3ea"
   },
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, c10_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix, c10_classes,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9LD2wIeYkMT"
   },
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQNFTsluYkMT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTpAv4uTYkMT"
   },
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEPSKD7vYkMU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
